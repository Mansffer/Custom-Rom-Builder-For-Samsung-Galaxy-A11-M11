name: Custom Rom Builder Samsung Galaxy A11/M11

on:
  push:
    branches:
      - main  # Change this to your desired branch
  workflow_dispatch:
    inputs:
      GSI:
        description: 'direct link for Gsi image '
        required: true
        default: 'https://sourceforge.net/projects/andyyan-gsi/files/lineage-19.x/lineage-19.1-20230715-UNOFFICIAL-a64_bgN.img.xz'        
      ARCH:
        description: 'ARM64 or ARM32?'
        required: true
        default: '64'                
      NAME:
        description: 'Rom Name'
        required: true
        default: 'LineageOS_19.1_A11_M11_ARM64_Gapps'                

jobs:
  Build:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v2

    - name: Install Dependencies
      run: |
        sudo apt update
        sudo apt-get install jq
        sudo apt install -y zip xz-utils unzip p7zip-full wget
        
    - name: Preparing Files
      run: |
        wget https://sourceforge.net/projects/samsung-galaxy-a01-m01/files/a11q.zip
        git clone https://github.com/smiley9000/Custom-Rom-Builder-For-Samsung-Galaxy-A11-M11
        unzip a11q.zip
        rm -r a11q.zip

    - name: Downloading your GSI
      run: |
        wget -P "./temp" ${{ github.event.inputs.GSI }} 
        chmod 755 *
        chmod 755 ./bin/*

    - name: Building
      run: |
        ./arm${{ github.event.inputs.ARCH }}_git

    - name: Uploading The Zip to Artifact
      uses: actions/upload-artifact@v4
      with:
        name: ${{ github.event.inputs.NAME }}   # Replace with a suitable name
        path: ./zip/Custom_Rom_SDM450.zip
        
    - name: Uploading The Zip to Dropbox
      run: |
        CHUNK_SIZE=157286400  # 150 MB por chunk
        FILE_PATH="./zip/Custom_Rom_SDM450.zip"
        if [ -f "$FILE_PATH" ]; then
          echo "Uploading $FILE_PATH to Dropbox using chunked upload..."
          FILE_SIZE=$(stat -c%s "$FILE_PATH")

          # Iniciar upload de sessão
          SESSION_ID=$(curl -X POST https://content.dropboxapi.com/2/files/upload_session/start \
            --header "Authorization: Bearer ${{ secrets.DROPBOX_ACCESS_TOKEN }}" \
            --header "Dropbox-API-Arg: {\"close\": false}" \
            --header "Content-Type: application/octet-stream" \
            --silent | jq -r ".session_id")

          # Verificar se SESSION_ID foi criado corretamente
          if [ -z "$SESSION_ID" ]; then
            echo "Erro ao iniciar sessão de upload no Dropbox. Aborting."
            exit 1
          fi

          OFFSET=0

          # Upload em partes
          while [ $OFFSET -lt $FILE_SIZE ]; do
            NEXT_CHUNK_SIZE=$((FILE_SIZE - OFFSET))
            if [ $NEXT_CHUNK_SIZE -gt $CHUNK_SIZE ]; then
              NEXT_CHUNK_SIZE=$CHUNK_SIZE
            fi

            dd if="$FILE_PATH" bs=$NEXT_CHUNK_SIZE skip=$((OFFSET / CHUNK_SIZE)) count=1 iflag=fullblock 2>/dev/null | \
            curl -T - -X POST https://content.dropboxapi.com/2/files/upload_session/append_v2 \
              --header "Authorization: Bearer ${{ secrets.DROPBOX_ACCESS_TOKEN }}" \
              --header "Dropbox-API-Arg: {\"cursor\": {\"session_id\": \"$SESSION_ID\", \"offset\": $OFFSET}, \"close\": false}" \
              --header "Content-Type: application/octet-stream" \
              --header "Transfer-Encoding: chunked"

            OFFSET=$((OFFSET + NEXT_CHUNK_SIZE))
            echo "Uploaded chunk, new offset: $OFFSET"
          done

          # Finalizar upload
          curl -X POST https://content.dropboxapi.com/2/files/upload_session/finish \
            --header "Authorization: Bearer ${{ secrets.DROPBOX_ACCESS_TOKEN }}" \
            --header "Dropbox-API-Arg: {\"cursor\": {\"session_id\": \"$SESSION_ID\", \"offset\": $OFFSET}, \"commit\": {\"path\": \"/${{ github.event.inputs.NAME }}-${{ github.run_id }}/Custom_Rom_SDM450.zip\", \"mode\": \"add\", \"autorename\": true, \"mute\": false, \"strict_conflict\": false}}" \
            --header "Content-Type: application/octet-stream"
        else
          echo "File $FILE_PATH does not exist and will not be uploaded."
        fi
